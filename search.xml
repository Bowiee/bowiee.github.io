<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[生成极大团子图]]></title>
    <url>%2F2019%2F08%2F12%2F%E7%94%9F%E6%88%90%E6%9E%81%E5%A4%A7%E5%9B%A2%E5%AD%90%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[参考资料：不确定图上求极大团算法不确定图上的枚举算法研究 不确定图：不确定图就是指边或者顶点信息中带有不确定性的图，这种不确定性通常是通过给边赋予权值来量化。用一个三元组 G=(V, E, β)表示一个不确定图，其中 β 表示边的权值，0&lt; β &lt;1，代表边存在的概率。如图所示不确定图中，每一条边都拥有权值，用来表示该边在实际应用中存在的概率，所以它是一个不确定图。1，图的存储结构用什么好？确定为邻接vector存储结构，因为vector作为STL中的类，封装了很多函数，用起来很方便。2，运行时遇到错误：vector subscript out of range？应该是有vector没有分配足够的空间，但是却用了它的下标。 我们这里是把不确定图当确定图（也就是普通的图），来处理的，并没由考虑边上的概率。之所以是用的不确定图，主要是因为我最近研究的是不确定图，把不确定图的数据结构换成确定图的，也是一样的。 下边是头文件： 12345678910111213141516Vertex_Value.h#pragma once#include &lt;iostream&gt;using namespace std;//这个相当于临接表中的边界点class Vertex_Value&#123;public: Vertex_Value(void); ~Vertex_Value(void); Vertex_Value(int x, float y);public: int vertex; //邻接表中边结点的编号 float val; //结点之间的概率&#125;; 123456789101112131415node.h#pragma once#include &quot;Vertex_Value.h&quot;#include &lt;vector&gt;using namespace std;//相当于头结点class node&#123; //public: // node(void);空参的构造方法，以及析构函数可以不用写，系统会自动实现 // ~node(void);public: int vertex; //头节点的结点编号 vector&lt;Vertex_Value&gt; vec; //这里用vector动态数组来放边结点，Vertex_Value表示边结点，其中有结点编号，以及边上的概率&#125;; 12345678910111213UDG.h#pragma once#include &quot;node.h&quot;class UDG&#123; //public: // UDG(void); // ~UDG(void);public: int vernum, arcnum;//结点数目和边的数目 node *AdjVector;//是邻接vector的形式 一个数组名字叫AdjVector,数组里面存放的是node形式的的数据&#125;; 12345678910111213ReadFile.h#pragma once#include &quot;UDG.h&quot;#define path &quot;F:\\c++_code\\test1.txt&quot;//文件路径//读取文件class ReadFile&#123;public: ReadFile(void); ~ReadFile(void); void CreateUdg(UDG &amp;g); //读取文件后，构建出不确定图出来&#125;; 12345678910111213141516171819202122232425BasicFunctions.h#pragma once#include &lt;vector&gt;#include &quot;UDG.h&quot;#include &quot;Vertex_Value.h&quot;using namespace std;#define $ 0.1 //概率阈值，这里我把图当作是确定的，所以不考虑概率。class BasicFunctions&#123;public: BasicFunctions(void); ~BasicFunctions(void); void Bron_Kerbosch(const UDG g);//把不确定图作为确定图来看待，得到所有的极大团子图 bool IfConnect(int u, int v, UDG g); //判断在图g中，结点u和结点v是否连接 void Enum_Deterministic(vector &lt;int&gt; all, vector &lt;int&gt; some, vector &lt;int&gt; none, UDG g);//用在Bron_Kerbosch算法中，枚举图中的极大团 vector&lt;int&gt; GenerateSome(vector &lt;int&gt; all, vector &lt;int&gt; some, int v ,UDG g);//用在Enum_Deterministic中，更新其中的some集合 vector&lt;int&gt; GenerateNone(vector &lt;int&gt; all, vector &lt;int&gt; none, int v, UDG g);//用在Enum_Deterministic中，更新其中的none集合&#125;; 下面是cpp文件 1234567891011121314Vertex_Value.cpp#include &quot;Vertex_Value.h&quot;Vertex_Value::Vertex_Value(void)&#123;&#125;Vertex_Value::~Vertex_Value(void)&#123;&#125;Vertex_Value::Vertex_Value(int x, float y)&#123; vertex = x; val = y;&#125; 1234567891011121314151617181920212223242526272829303132333435ReadFile.cpp#include &quot;ReadFile.h&quot;#include &lt;fstream&gt;#include &lt;iostream&gt;using namespace std;ReadFile::ReadFile(void)&#123;&#125;ReadFile::~ReadFile(void)&#123;&#125;void ReadFile::CreateUdg(UDG &amp;g)&#123; ifstream infile(path); //读取path里面的文本 cout &lt;&lt; &quot;开始读入文件！&quot; &lt;&lt; endl; infile &gt;&gt; g.vernum &gt;&gt; g.arcnum; //infile在这里就类似cin操作，cin是读取键盘输入，而infile是读取文件输入 &gt;&gt; 操作返回的是左操作数，也就是给g.vernum和g.arcnum赋值了 cout &lt;&lt; &quot;顶点个数和边数为：&quot; &lt;&lt; endl; cout &lt;&lt; g.vernum &lt;&lt; &apos; &apos; &lt;&lt; g.arcnum &lt;&lt; endl; g.AdjVector = new node[g.vernum + 1];//0号不存结点，能储存g.vernum个结点的数组AdjVector，g.AdjVector[0]中不存放数据 cout &lt;&lt; &quot;开始读入边，建立邻接vector！&quot; &lt;&lt; endl; int i; for (i = 0; i &lt; g.arcnum; i++) &#123; int head, tail; float val; infile &gt;&gt; head &gt;&gt; tail &gt;&gt; val; //文本里读取文件到空格结束，循环结束以后进入到下一行 g.AdjVector[head].vertex = head; //这样可以完成顺序存放，这样g.AdjVector[1]中，存放的是头节点为1的结点，其他结点也都是对应的 Vertex_Value temp; temp.vertex = tail; temp.val = val; g.AdjVector[head].vec.push_back(temp); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150BasicFunctions.cpp#include&lt;algorithm&gt;#include &lt;iterator&gt; #include &quot;UDG.h&quot;#include &quot;BasicFunctions.h&quot;BasicFunctions::BasicFunctions(void)&#123;&#125;BasicFunctions::~BasicFunctions(void)&#123;&#125;//***********************************************************************//判断在图g中结点u和结点v是否相连bool BasicFunctions::IfConnect(int u, int v, UDG g)&#123; int i; unsigned int j; for (i = 1; i &lt;= g.vernum; i++) &#123; if (g.AdjVector[i].vertex == u) &#123; break; &#125; &#125; for (j = 0; j &lt; g.AdjVector[i].vec.size(); j++) &#123; if (v == g.AdjVector[i].vec[j].vertex) &#123; //cout &lt;&lt; &quot;结点&quot; &lt;&lt; u &lt;&lt; &quot;和结点&quot; &lt;&lt; v &lt;&lt; &quot;相连&quot; &lt;&lt; endl; return true; &#125; &#125; //cout &lt;&lt; &quot;结点&quot; &lt;&lt; u &lt;&lt; &quot;和结点&quot; &lt;&lt; v &lt;&lt; &quot;不相连&quot; &lt;&lt; endl; return false;&#125;//***********************************************************************//用在Enum_Deterministic中，更新其中的none集合vector&lt;int&gt; BasicFunctions::GenerateNone(vector &lt;int&gt; all, vector &lt;int&gt; none, int v, UDG g)&#123; if (none.empty()) &#123; return none; &#125; unsigned int i; vector&lt;int&gt; _none; for (i = 0; i &lt; none.size(); i++) &#123; if (IfConnect(v, none[i], g)) &#123; _none.push_back(none[i]); &#125; &#125; return _none;&#125;//***********************************************************************//用在Enum_Deterministic中，更新其中的some集合vector&lt;int&gt; BasicFunctions::GenerateSome(vector &lt;int&gt; all, vector &lt;int&gt; some, int v, UDG g)&#123; if (some.empty()) &#123; return some; &#125; unsigned int i ; vector&lt;int&gt; _some; for (i = 0; i &lt; some.size(); i++) &#123; if (IfConnect(v, some[i], g)) &#123; _some.push_back(some[i]); &#125; &#125; return _some;&#125;//***********************************************************************//用在Bron_Kerbosch算法中，枚举图中的极大团void BasicFunctions::Enum_Deterministic(vector &lt;int&gt; all, vector &lt;int&gt; some, vector &lt;int&gt; none, UDG g)&#123; unsigned int i; if (some.empty() &amp;&amp; none.empty()) //两者都为空，则找到极大团 &#123; cout &lt;&lt; &quot;产生一个极大团！&quot; &lt;&lt; endl; for (i = 0; i &lt; all.size(); i++) &#123; cout &lt;&lt; all[i] &lt;&lt; &apos; &apos;; &#125; cout &lt;&lt; endl; return; &#125; int u; if (!some.empty())//因为可能会存在着，some已经为空了，但是none不为空的情况，这时，直接u=some[0]赋值，会报错 &#123; u = some[0]; &#125; vector&lt;int&gt; allTemp(all); //将all中的所有值，都赋给allTemp，allTemp用来递归到下一层（去放置极大团） for (i = 0; i &lt; some.size(); i++) &#123; int v = some[i]; if (IfConnect(u, v, g)) continue; //如果u和v相连，就进入下一轮循环，不再执行下面代码 allTemp.push_back(some[i]);//更新下一层中的allTemp vector&lt;int&gt; _some = GenerateSome(allTemp, some, v, g);//产生新的some集合。要保证新的some集合，要和allTemp集合中的所有结点都连接 vector&lt;int&gt; _none = GenerateNone(allTemp, none, v, g);//产生新的none集合。要保证新的none集合，要和allTemp集合中的所有结点都连接 Enum_Deterministic(allTemp, _some, _none, g); //带着新的all,some,none集合进入到下一层中 none.push_back(some[i]);//将some[i]放入none中，表示在这一层里面，由some[i]开始的极大团，已经探索过了 some[i] = 0; allTemp.pop_back(); //将some[i]从allTemp中拿出，开始下一轮的for循环，在下一轮的for循环中，放入新的some[i] &#125;&#125;//***********************************************************************//总算法的第一步，从原图中得到所有的极大团子图void BasicFunctions::Bron_Kerbosch(const UDG g)&#123; vector &lt;int&gt; some(g.vernum);//声明一个初始大小为g.vernum的Vertex_Value类型的向量_I，_I中存放的结点，就是预备要放入C中的 vector&lt;int&gt; all; //声明一个int型向量all，就是极大团 vector&lt;int&gt; none; //声明一个Vertex_Value型向量X ，X存放已经探索过的某结点。 int i = 1; for (i; i &lt;= g.vernum; i++) &#123; some[i - 1] = i; //将所有的结点编号存放在some中 &#125; Enum_Deterministic(all, some, none, g);&#125; 下面是主函数： 1234567891011121314151617#include &lt;tchar.h&gt;#include &quot;ReadFile.h&quot;#include &quot;BasicFunctions.h&quot;#include &lt;iostream&gt;using namespace std;int _tmain(int argc, _TCHAR* argv[])&#123; UDG g; ReadFile A; A.CreateUdg(g); BasicFunctions BF; BF.Bron_Kerbosch(g); system(&quot;pause&quot;); //暂停黑窗口 return 0;&#125; test.txt如下:9表示结点数，22表示边数（这里的1 2和2 1算不同的边）第一位数字是头结点，第二位数字是边结点，第三个数字是边上的概率 12345678910111213141516171819202122239 221 2 0.61 3 0.52 1 0.62 3 0.42 5 0.73 1 0.53 2 0.43 4 0.53 5 0.14 3 0.54 5 0.25 2 0.75 3 0.15 4 0.25 6 0.46 5 0.46 7 0.76 8 0.96 9 0.87 6 0.78 6 0.99 6 0.8 实验结果：]]></content>
      <categories>
        <category>知识总结</category>
      </categories>
      <tags>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[求极大团的Bron-Kerbosch算法]]></title>
    <url>%2F2019%2F08%2F07%2FBron-Kerbosch%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[不了解极大团(maximal clique)的，请看极大团这篇文章。该算法是由Coen Bron和Joep Kerbosch在1973提出的，论文原文参考资料：Bron-Kerbosch算法视频介绍极大团算法当给出一个图之后，我们应该怎么去找出其中的极大团呢？寻找极大团的简单思想就是：1、生成原始图的所有子图(可能有2n-1个子图，n表示结点个数)；2、判断这些子图是不是团；3、将不是极大团的团都删除；在我们上面给出的图中，会有许多的子图，例如：这里没有列出所有的子图，只有部分。在这些子图里面，我们会发现有些并不是团，例如{1、2、3}组成的图，因为2和3之间并不相连，所以这样的图不符合要求，将其去掉。剩下的所有子图，都是满足了团的要求的图。最后，其中还有许多，不是极大团的，例如{0、1}就不是极大团，因为有{0、1、2}的存在。这些不是极大团的团，我们也要去掉。现在剩下的就是我们要找的极大团。 Bron-Kerbosch算法(Version 1)这个算法主要是构造了三个集合，我们假设：R集合记录的是当前极大团中已经加入的点。P集合记录的是可能还能加入的点（也就是与R集合中所有点都有边存在的点，这样加入后，才会构成团）X集合记录的是已经加入过某个极大团的点（作用是判重，因为会从每个结点开始，枚举所有的团，如果不对已经加入某个极大团的点，进行标记，可能会有重复的极大团出现）伪代码如下： 123456789101112Bron-Kerbosch Algorithm(Version 1)R=&#123;&#125; //已确定的极大团顶点的集合P=&#123;v&#125; //未处理顶点集，初始状态是所有结点X=&#123;&#125; //已搜过的并且属于某个极大团的顶点集合BronKerbosch(R, P, X): if P and X are both empty: report R as a maximal clique for each vertex v in P: BronKerbosch1(R ⋃ &#123;v&#125;, P ⋂ N(v), X ⋂ N(v)) P := P \ &#123;v&#125; X := X ⋃ &#123;v&#125; 基础的Born_Kerbosch算法：1、对于每一个在集合P中的点v，我们把v加入集合R（集合P中的点与集合R中所有的点都是连接的，这样加入v，保证集合R依然是一个团），对在P集合中且与点v相连的这部分集合中寻找下一个可能加入R集合的点（意思就是更新P集合，使P集合中的点依旧可以和R集合中的点相连接，因为这里新R集合新加入了v，所以只要是原P集合中且与v相连的，那这些结点就是与新的R集合中所有结点都相连）。2、回溯时我们把v从P集合中移出，加入X集合代表当前状态下对包含点v的极大团已经计算完毕了。3、R集合为极大团的时候，必须要满足P与X都是空的。P存放的是还可能加入R集合的点，P集合为空代表没有点还能再加入到R集合当中，而X集合存放的是已经完成极大团计数的点，而且X集合中的点必然是与所有R集合中的点都有边存在的(因为我们每次向下进行dfs的时候，还对P集合和X集合分别进行取与R集合内都相邻的操作来保证，而且加入X集合中的点，就是从R集合中取出来的，当然会和R集合中的所有结点都有边)，也即X集合中点必然可以与R集合构成极大团。如果X集合不是空的的话，可以把X集合中的点加入R集团，此时R集团依然是团，结点数比刚才增加了，说明刚才的R集合就不是极大团，那么说明R集合中的极大团是在之前计算包含X集合中的点的极大团的时候已经计算过了的，故当且仅当P、X都为空集合的时候R才是一个极大团。 算法的实例：在最开始中，集合P会初始化为所有的结点，其他集合为空集。首先，我们将集合P中的第一个结点，1号结点，放入到R中。这个时候，我们的遍历要进入下一层了，所以要更新集合P和集合X，这里集合X没有变化，依然是空集。集合P中的点要是和集合R中的所有结点都是连接的，显然我们只需要找到，原来的P集合中是1号集合的邻居结点的那些点就行了，这里就是{2、3}，保证了P集合中的每个结点都可以和R集合中的结点想连接，其实X集合我们也会执行同样的操作，以保证X集合中的结点都是和R集合中的所有结点连接的。同样的，我们继续将P集合中的结点放入R集合，这次放入2号结点，R集合变为{1、2}，P集合取原P集合中且和2号结点相连接的结点，P集合就变为{3}。最后同样的我们将P集合中的结点，放入R集合。此时P集合X集合都为空集，说明这个团已经不能再扩充了，所以{1、2、3}就是一个极大团。&emsp;&emsp;我们从1号结点开始，先遍历了{1、2}，所以还要从1开始遍历{1、3}。按照DFS的规则，会先退回到上一层，也就是R={1、2}，P={3}这一层，我们会将v结点，也就是这一层里操作的结点，在这里是3号结点放入X集合中，表示它已经参与了极大团的构。在这一层里最后就变为了R={1、2}，P={}，X={3}，因为X不为空，且P为空，所以R={1、2}不是一个极大团，然后我们要回溯到上一层了，也就是R={1}、P={2、3}、X={}这一层，再将此时的操作结点2号结点，放入X中，表示它已经属于某个极大子图，这时的三个集合变为了R={1},P={3},X={2}。 &emsp;&emsp;只要P集合中，还有元素，我们就会一直执行将P集合中的元素加入R集合中的操作，所以这里将3号结点加入，并且更新了P集合和X集合（就是保证P,X中的结点和R集合中的所有结点都连接）进入下一层，也就是图中所示的样子。 &emsp;&emsp;在这里X={2}，不为空，所以{1、3}不是极大团，因为X集合中的在加入R集合后，都是会让R集合满足极大团的，显然{1、2、3}比{1、3}要大，所以只要X不为空，R就不会是极大团。&emsp;&emsp;在完成判断后，退回到上一层，也就是图中的R={1}，P={2、3}，X={}的这一层，不过刚才有说过，这一层其实在经过将P中的2号结点加入到R后，以及后续的程序，已经变成了R={1},P={3},X={2},此时我们将正在操作的结点3号结点放入到X中，变为R={1}，P={}，X={2、3}，此时P中无结点，X中有两个结点。说明以1开始的遍历操作以及全部完成了，我们需要再去寻找其他结点开始的遍历。&emsp;&emsp;退回到上一层，也就是最开始的那一层，即R={}、P={1、2、3、4}、X={}的这一层。把操作的结点，也就是1号结点，放入X中，表示已经对其进行过查询。&emsp;&emsp;再将P中的下一个结点，也就是2号结点，放入R中，同样的我们要更新P和X，保证P和X中的结点，和R中的所有结点，都是连接的，进入下一层，得到的如图所示，R={2}、P={3、4}、X={1}，表示我们要由2号结点开始，寻找极大团了。&emsp;&emsp;同样的，我们将P中的3号结点放入R中，同时更新P和X，因为P中的4号结点，不与3号结点相连，所以P集合变为空集，X依然为{1}。此时我们发现P为空，但是X={1}，所以R={2、3}并不是一个极大团。这说明由2开始，再走3号结点这条路是行不通的，所以需要退回到上一层，也就是R={2}、P={3、4}、X={1}这一层，再将3号结点放入X中，表示已经搜过了，此时变为R={2}，P={4}，X={1、3}。下面就要走由2号结点开始，在到4号结点的这条路了。将P中的4号结点放入R中，同时更新P和X，因为1和3都不与4相连，所以X集合变为空集，此时P集合也为空集，所以R={2、4}是一个极大团。我们的遍历当然还要继续，我们现在找了从最初的图中，由1开始，已经由2开始来寻找极大团，当然还要从3开始以及从4开始，寻找极大团，结果如图所示。由3号结点开始，R={3}、P={}、X={1、2}；由4号结点开始，R={4}、P={}、X={2}。X集合都不为空，所以R集合不是极大团。每一次遍历中，所生成的集合如上图的右下角所示，可以很明显的看出两个极大团。Bron-Kerbosch Algorithm(Version 1)完整的代码为： 12345678910111213141516171819202122232425262728int some[maxn][maxn]; //some表示P集合，第一个[maxn]表示所在的深度，后一个就是P集合中的某个结点的位置int none[maxn][maxn]; //表示X集合，其他和some同理int all[maxn][maxn]; //表示R集合，其他同理int mp[maxn][manx]; void dfs(int d, int an, int sn, int nn)//d为搜索深度，an、sn、nn分别为all(R)、some(P)、none(X)集合中顶点数，&#123; if(!sn &amp;&amp; !nn) ++ S; //sn==0，nn==0时，是一个极大团，S为极大团数量 for(int i = 0; i &lt; sn; ++i) //遍历P中的结点，sn==0时，搜索到终点 &#123; int v = some[d][i]; //取出P中的第i个结点 for(int j = 0; j &lt; an; ++j) all[d+1][j] = all[d][j]; all[d+1][an] = v; //这里是将取出的v结点，添加到R集合中，当然是添加到下一个深度的R集合。 int tsn = 0, tnn = 0; //用来分别记录下一层中P集合和X集合中结点的个数 for(int j = 0; j &lt; sn; ++j) if(mp[v][some[d][j]]) some[d+1][tsn++] = some[d][j]; //更新P集合(当然是下一层的P集合)，保证P集合中的点都能与R集合中所有的点相连接 for(int j = 0; j &lt; nn; ++j) if(mp[v][none[d][j]]) none[d+1][tnn++] = none[d][j]; //更新X集合(当然是下一层的X集合)，保证X集合中的点都能与R集合中所有的点相连接 dfs(d+1, an+1, tsn, tnn); //递归进入下一层 some[d][i] = 0, none[d][nn++] = v; //完成后，将操作的结点，放入X中，开始下面的寻找。 &#125;&#125; Bron-Kerbosch 算法(Version 2)&emsp;&emsp;在上面这个方法中，我们进行了许多不必要的判断，例如在我们找到了极大团{1、2、3}之后，依然去对{1、3}，{2、3}，{3}这些团进行了判断，然而这些显然不是极大团。所以现在考虑的是对其进行优化，使程序不用进行不必要的递归。 &emsp;&emsp;当我们将一个结点u，放入到R集合后，再取下一个结点，取的必然是u的邻居结点（因为再更新P和X时，会将不是邻居结点的结点都过滤掉）。通俗的讲就是如果取完u之后我们再取与u相邻的点v也能加入到极大团，那么我们只取u就好了，因为我们由u开始递归，已经找到了u及其邻居结点v等等结点构成的极大团了，没有必要再去从v开始寻找极大团，这会增加不必要的计算。至于v可能可以其他结点构成另一个极大团，如果这个极大团包括了u，那么由u开始就已经找到了这个极大团了；如果这个极大团不包括u,那说明这个极大团里面一定存在和u结点不相连的结点k，那没必要从v开始寻找这个极大团了，从u的非邻居结点k开始，一样可以找到这个极大团。这样对u及其邻居结点构成的极大团，只需要从u开始寻找一次就可以了，接下来就直接从u的非邻居结点k开始寻找极大团，这样可以减少许多不必要的计算。 &emsp;&emsp;例如上面的程序中我们从1开始寻找极大团，找到了由1及其邻居结点构成的极大团{1、2、3}，接下来我们就直接从1的非邻居结点4号结点开始寻找极大团，可以找到极大团{4、2}，最终所有的极大团都被找到了。其中由2和3开始的这些不必要的计算都被省略，当然在递归的内部，我们也依然使用这种思想。而我们要想进一步减少计算，我们就可以取邻居尽可能多的u，这样让我们要遍历的点尽可能减少，但是其实没必要如此，寻找合适的u也会减少一定的效率。设定关键点 pivot vertex u，只对关键点u自身和u的非邻居结点进行查找。伪代码如下： 12345678910111213Bron-Kerbosch Algorithm(Version 2)R=&#123;&#125; //已确定的极大团顶点的集合P=&#123;v&#125; //未处理顶点集，初始状态是所有结点X=&#123;&#125; //已搜过的并且属于某个极大团的顶点集合BronKerbosch(R, P, X): if P and X are both empty: report R as a maximal clique choose a pivot vertex u in P ⋃ X for each vertex v in P \ N(u): BronKerbosch1(R ⋃ &#123;v&#125;, P ⋂ N(v), X ⋂ N(v)) P := P \ &#123;v&#125; X := X ⋃ &#123;v&#125; 下图是Bron-Kerbosch Algorithm(Version 1)和Bron-Kerbosch Algorithm(Version 2)的对比在右边是没有优化的方法，我们可以看到递归的次数非常的多，有太多不必要的计算。左边就是优化后的方法，下面讲解其中的具体步骤：&emsp;&emsp;这里每次会选择邻居结点多的那个结点当作Pivot，所以一开始选择4号结点做Pivot，我们也从4号结点开始进行递归，所以进入下一层，得到R={4}，P={1、2、3、5、6}，X={}，P中的结点经过筛选以后，将7号结点去除。&emsp;&emsp;我们从P中选2号结点（因为2号结点邻居结点多），同时也将2号结点作为这一层的Pivot 结点，同时更新P集合。这一层变为{4、2}，{1、3、5}，{}。&emsp;&emsp;我们从P中选1号结点（因为1号结点邻居结点多，当然这里向图中一样选5号结点也是可以的），同时也将1号结点作为这一层的Pivot 结点，同时更新P集合。这一层变为{4、2、1}，{3}，{}。&emsp;&emsp;最后将P集合中的3号结点，放入R集合，此时P集合和X集合都变为空集，所以{4、2、1、3}是极大团。到目前位置，我们的操作步骤和优化之前是一样的，只是这里每次都是选取的邻居最多的结点放入（这样是为了尽可能的减少递归次数，其实按照原来的顺序也是可以的）。和之前一样的原因是，这是第一轮递归，我们在每一层放入R集合的结点，就是该层的Pivot 结点。&emsp;&emsp;因为P={}，所以退回到上一层，也就是{4、2、1}，{3}，{}，然后将P中的结点3放入到X中，表示在这条路上，已经探索过这个结点了。于是变为{4、2、1}，{}，{3}，P集合为空集，所以退回到上一层，也就是{4、2}，{1、3、5}，{}，将1号结点移入X集合中，变为{4、2}，{3、5}，{1}，然后在P中选取下一个结点加入R集合中，在这一层中Pivot结点是1号结点（图中为5号结点，所以多了一步，就是{4、2、3}，{}，{}这一步），所以凡是在P集合中并且是Pivot结点（也即是这里的1号结点）的邻居结点的，从P集合中移除。比如这里3号结点在P集合中，且3号结点是1号结点的邻居结点，所以将3号结点移除（因为我们已经通过1号结点，找到了同时包含1和3的极大团）。&emsp;&emsp;最后P集合中只有5号结点了，所以将5号结点放入R集合中，并且更新P和X，变为{4、2、5}，{}，{}，此时P和X都为空集，所以{4、2、5}是一个极大团。由4、2开始的这一层，我们已经探索完了，所以要退回到{4}，{1、2、3、5、6}，{}这一层。&emsp;&emsp;在这一层里，Pivot结点是2号结点，所以P集合中和2是邻居结点的那些结点将不会在放入R集合中，所以将P集合中的6放入R集合中，更新P集合与X集合，得到{4、6}，{}，{}，所以{4、6}是一个极大团。&emsp;&emsp;现在由4开始的这条路径，我们也全部都走完了，所以需要退回到最开始的那一层，也就是{}，{1、2、3、4、5、6、7}，{}，将4号结点放入X集合中，找到P集合中不和4号结点相连的那些结点，这里只有7号结点，所以将7号结点放入到R集合中，同时更新P和X，得到{7}，{5}，{}，这里只有5号结点了，显然选择5号作为Pivot，最后变为{7、5}，{}，{}，所以{7、5}就是一个极大团。&emsp;&emsp;现在，已经找出了图中所有的极大团，而且从图中可以明显的看出，我们递归的次数是比原来要少很多的。Bron-Kerbosch Algorithm(Version 2)完整的代码为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;cstdio&gt;#include &lt;cstring&gt;using namespace std;const int maxn = 130;bool mp[maxn][maxn]; //表示结点之间的连接int some[maxn][maxn], none[maxn][maxn], all[maxn][maxn];//分别是P集合，X集合，R集合int n, m, ans; //n表示结点数，m表示边数，ans表示极大团数量void dfs(int d, int an, int sn, int nn)&#123; if(!sn &amp;&amp; !nn) ++ans; int u = some[d][0]; //选取Pivot结点 for(int i = 0; i &lt; sn; ++i) &#123; int v = some[d][i]; if(mp[u][v]) continue; //如果是邻居结点，就直接跳过下面的程序，进行下一轮的循环。显然能让程序运行下去的，只有两种，一种是v就是u结点本身，另一种是v不是u的邻居结点。 for(int j = 0; j &lt; an; ++j) all[d+1][j] = all[d][j]; all[d+1][an] = v; int tsn = 0, tnn = 0; for(int j = 0; j &lt; sn; ++j) if(mp[v][some[d][j]]) some[d+1][tsn++] = some[d][j]; for(int j = 0; j &lt; nn; ++j) if(mp[v][none[d][j]]) none[d+1][tnn++] = none[d][j]; dfs(d+1, an+1, tsn, tnn); some[d][i] = 0, none[d][nn++] = v; if(ans &gt; 1000) return; // 极大团数量超过1000就不再统计 &#125;&#125;int work()&#123; ans = 0; for(int i = 0; i &lt; n; ++i) some[1][i] = i+1; dfs(1, 0, n, 0); return ans;&#125;int main()&#123; while(~scanf(&quot;%d %d&quot;, &amp;n, &amp;m)) &#123; memset(mp, 0, sizeof mp); for(int i = 1; i &lt;= m; ++i) &#123; int u, v; scanf(&quot;%d %d&quot;, &amp;u, &amp;v); mp[u][v] = mp[v][u] = 1; &#125; int tmp = work(); if(tmp &gt; 1000) puts(&quot;Too many maximal sets of friends.&quot;); else printf(&quot;%d\n&quot;, tmp); &#125; return 0;&#125;]]></content>
      <categories>
        <category>知识总结</category>
      </categories>
      <tags>
        <tag>论文</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极大团]]></title>
    <url>%2F2019%2F08%2F04%2F%E6%9E%81%E5%A4%A7%E5%9B%A2%2F</url>
    <content type="text"><![CDATA[参考资料：Bron-Kerbosch算法视频介绍极大团介绍团、极大团介绍 团(clique)引自wiki： a clique is a subset of vertices of an undirected graph such that every two distinct vertices in the clique are adjacent.意思就是团(clique)就是一个无向图的完全子图，既然是完全图，当然每对顶点之间都必须要有边相连。 12团：无向图的完全子图。完全图：完全图是一个简单的无向图，其中每对不同的顶点之间都恰连有一条边相连。 给出上图所示的无向图，其中存在着许多的团。比如这里的{0、5}就是一个团，它就是原图的一个完全子图，并且结点之间连接，当然{0、4、5}，{1、2、4}同样也是团，团里面的结点都必须是互相连接的。还有许多的团并没有全部列举出来，比如{0、4}，{1、2}，{4、3}等等。 极大团(maximal clique)引自百度百科：如果一个团不被其他任一团所包含，即它不是其他任一团的真子集，则称该团为图G的极大团（maximal clique）在我给出的这个图里面，极大团应该有哪些呢？我们刚才所说{0、5}和{0、5、4}都是团，但是对于{0、5}来说，当我们把结点4添加进去以后，依然可以构成一个团{0、5、4}所以{0、5}不是一个极大团，而对于{0、5、4}我们在图中已经不能找到一个结点添加进去，可以让其构成团了，所以{0、5、4}是一个极大团。图中共有4个极大团，对于这些团，都无法在原图中找到一个结点，加入其中，会使其成为一个新团。所以他们都是极大团。 最大团(maximum clique)最大团就是就是结点数最多的极大团。我们刚才已经列出了所有的极大团，显然最大团就是有三个结点的这三个团。最大团就是在全局上最大的团（也就是结点最多）极大团就是在局部上最大的团。]]></content>
      <categories>
        <category>知识总结</category>
      </categories>
      <tags>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论：快速排序]]></title>
    <url>%2F2019%2F08%2F02%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[快速排序基本思想输入代排数组——&gt;选取基准元——&gt;执行划分操作——&gt;递归对两个数组进行快速排序1、比如这里输入序列{72，6，57，88，60，42，83，73，48}2、下面选取基准元，这里选取72选取基准元后，会用另一个空间存放基准元的数据，用两个指针分别指向数组最前端与最后端，从最后端开始比较，如果比基准元72小，则放在基准元前面，也就是将数据放在前端指针指的数据，这里是48&lt;72所以要放在第一个位置。3、执行划分操作再移动前端指针，依次进行数据的改变，当前后指针指向同一个数据时，就是划分结束，将基准元的数据放在指针的位置。4、递归对两个数组进行快速排序现在依据第一次的基准元，将数组分为左右两个部分，分别对两个数组进行快速排序，基准元选择第一个数字，也就是48、83作为基准元。执行划分后得到上图，依次类推执行快速排序。经过三次划分后，得到了有序的序列。 快速排序优化方法选择基准的方式——固定位置1思想：取待排序列的第一个或最后一个作为基准 就是我们刚才举列子的方式，这种方式在最好的情况下，时间复杂度是O(nlgn)，不过在最坏情况下，也就是这个序列本身是有序的时候，这个排序就会变成冒泡排序，时间复杂度为O(n2) 选择基准的方式——随机选择基准1思想：取待排序列中的任意一个作为基准 简单分析： 基准元的位置是随机的，则出现最坏情况的概率大大降低，最好情况依然是O(nlgn)在整个数组数字全相等时，仍然是 最坏情况，时间复杂度是O(n2) 选择基准的方式——“三数取中”选取基准元这样可以尽可能让划分得到的两个序列尽可能等长，会降低快速排序的时间复杂度。 快速排序+插入排序原因：对于很小和部分有序的数组，快排不如插排好 “聚key”方法1思想：在一次分割结束后，可以把与Key相等的元素聚在一起，继续下次分割时，不用再对与key相等元素分割。 这里给出序列{1，4，6，7，6，6，7，6，8，6}，用三数取中的方法会选择出基准元6，最后划分出左右两个子序列。这个方法与其他方法的不同，就是在移动指针时，如果指针的值，和基准元一样，比如这里指向6，那就会将这个数移动到两端（哪一边的指针指向的，就移动到哪一段）。再将两端的key值，移动到与基准相等的地方，最后划分得到左右两个子序列。采用这种方法，能减少迭代次数，提高效率。 快排及其优化-总结在优化方面，主要集中在选取基准元和执行划分操作上。]]></content>
      <categories>
        <category>算法导论</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论：最大子序列和]]></title>
    <url>%2F2019%2F08%2F01%2F%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%88%97%E5%92%8C%2F</url>
    <content type="text"><![CDATA[算法导论：最大子序列和问题描述：什么是最大子序列和呢?就是给定一组序列，所有子序列中和最大的那一组序列。比如这里给出一组序列{-2，11，-4，13}这里列出了10个子序列。其中20就是我们要求的最大子序列和。关于最大子序列和有几个注意事项： 123空序列也是子序列，它的和为0；如果序列中所有整数均为负数，则最大子序列和为0;子序列一定是连续的; 穷举法11算法思想：穷举所有子序列，找最大的。 如上图所示，列出所有子序列，再找出其中最大的和，不过这其中会出现大量重复的计算，比如-2+11就计算了三遍，耗费大量时间，下面计算时间复杂度。假如是有n个数的序列，那它会有多少个子序列呢？从1开始的子序列有n个，从2开始的子序列有n-1个，所以总共的子序列为：现在我们知道了总序列数，也就是序列的个数，那这些序列和的计算次数是多少？由1开始的子序列有n个，从{1，2}一直到{1，2····n-1,n}，我们在计算这些序列和时，{1，2}相当于计算了1次，就是1+2。计算{1,2,3}时我们又计算了一次1+2，所以这次计算了2次，那由1开始的序列计算的次数就是1+2+····+n也就是图中所示的结果。2开始的序列的计算次数就是1+2···+n-1，以此类推求出所有序列的计算次数，最后得出总的计算次数。所以时间复杂度为O(n3) 穷举法21算法思想：在某点开始的所有序列中找最大的，找最大的。 比如这里给出一组序列{-2，11，-4，13}，首先计算由-2开始的所有子序列和，再找出其中最大的可以看到这种方法避免了穷举法1中每次都要从头开始相加而造成的大量浪费，下面我们依次计算由11，-4，13开始的序列，找出最大子序列和。在分别求出以-2，11，-4，13开始的最大子序列和后，再选择其中最大的那个，就是我们要找的最大子序列和。但是这其中依然包含了重复计算，如上图所示，计算由-2开始的序列时，我们计算了11+-4+13，在计算由11开始的序列时，也依然计算了11+-4+13，造成了重复计算。那所有这些序列的总共计算次数是多少呢？在穷举法2中，由1开始的序列有n个，但因为避免了穷举法1中的重复计算，所以计算次数只有n次，总共的计算次数就是1+2+···+n次，所以时间复杂度是O(n2)。 分治法1分治法的设计思想：将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。 给出一个序列{a,b,c,d,e,f,g}，显然最大子序列和只可能出现在三个地方： 123输入序列的左半部分；输入序列的右半部分；跨越输入序列的中部而位于左右两个部分； 所以我们只需要分别找出这三个部分的最大子序列和，再比较这三个和的大小，找出最大的子序列和即可。我们可以通过递归的方法找到左半部分最大子序列和lsum以及右半部分最大子序列和rsum。找到跨越中部的最大子序列和，因为这个子序列和一定是跨越中部的，所以只需要确定好中部，然后使lmax以及rmax都为最大，那么csum就是我们要找的子序列。最后比较这三个子序列的大小，最大的和就是最大子序列和。这里使用的是分治法，分治法的时间复杂度为O(nlgn)，详解请看分治法 动态规划法分析：1、因为最大子序列和的最小取值为0，所以最大子序列的第一个元素不会是负的。若a[i]&lt;0,则a[i]开头的序列，一定不如a[i+1]开头的序列大。2、同理任何负的子序列，不可能作为最大子序列和的前缀。这里的{4、-5}不能作为子序列的前缀。3、如若一个子序列和thisSum&gt;0（其中thisSum是从第m项到第n项的和），那么最大子序列和一定不会以a[m+1]和a[n]之间的项开始。这里{1、5、-3、2}这个序列和大于0，那么最大子序列和就不会是从5或者-3或者2开始的，因为由这些开始，加上前面的1会更大。下面将用介绍具体的例子：首先给出序列{-5、15、-2、13、-9、-1、9、-30、10、3}。用标记分别标出，子序列和的起始位置，最大子序列和起使以及终点位置，此时三个位置都在-5这里。并且记录下该时刻最大子序列和的值以及子序列和的值。当指针移动到15时，根据上面的第一条规则，最大子序列的第一个元素不为负数，所以此时三个标记都要移动到15，子序列的和为15，同时更新最大子序列的和15。当指针移动到-2时，更新此时的子序列和为13，发现13&lt;15,所以最大子序列和依然是15，且起使、终点位置也不改变。当指针移动到13时，子序列和变为26&gt;15，所以更新最大子序列和为26。并且最大子序列的终点位置也要发生变化。![动态规划]/(最大子序列和/18.png)在指针移动过-9、-1、9、-30时子序列和的值都没有26打，所以最大子序列和并未更新，不过指针移动到-30时子序列和变为了-5，也就是{15、-2、13、-9、-1、9、-30}和为-5，根据规则2，这个序列一定不会是最大子序列的前缀。而且{15、-2、13、-9、-1、9}这个序列的和是大于0的，根据规则3，最大子序列和一定不会是从{-2、13、-9、-1、9}这里面的某一项开始的。所以最大子序列和不会是以{15、-2、13、-9、-1、9、-30}为前缀开始的，也不会是以{15、-2、13、-9、-1、9、-30}中的某一项开始的。那么当我们下一步，移动子序列起使位置的标记时，就可以跳过这里面所有的数，移动到-30后面的数。子序列和的起使位置变为了10，10&lt;26，所以最大子序列和的值以及标记依然不发生变化。序列遍历完成后，可从记录中得知，最大子序列和为26，序列是{15、-2、13}。在整个过程中，我们只用指针遍历了一遍序列，并且做了简单的记录，所以动态规划算法的时间复杂度是O(n)。 总结穷举法1：算法思想：穷举所有子序列，找最大的。时间复杂度：O(n3)缺点：包含大量重复计算。穷举法2：算法思想：在某点开始的所有子序列中，找最大的。时间复杂度：O(n2)缺点：同样包含重复计算。分治法：算法思想：利用可分解、递归的性质，采用分治策略。时间复杂度：O(nlgn)动态规划法：算法思想：采用了动态规划的方法。时间复杂度：O(n)]]></content>
      <categories>
        <category>算法导论</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论：后缀树]]></title>
    <url>%2F2019%2F07%2F30%2F%E5%90%8E%E7%BC%80%E6%A0%91%2F</url>
    <content type="text"><![CDATA[算法导论：后缀树参考资料：在线构造后缀树Ukkonen’s Algorithm构造后缀树实录后缀树系列在阅读本文之前，需要了解字典树，请看字典树 1定义：后缀树是一棵压缩字典树，其次，后缀树中存储的关键词为所有的后缀。 下面将对后缀树的构建以及优化做出详细的介绍。 后缀树的构建列出字符串所有后缀以字符串S=MISSISSIPPI$为例S的所有后缀如下：S[0…11]= MISSISSIPPI$ &emsp; &emsp; &emsp; &emsp; &emsp; 字符串本身，起始位置0S[1…11]= &ensp; ISSISSIPPI$ &emsp; &emsp; &emsp; &emsp; &emsp;&emsp; 起始位置1S[2…11]= &emsp;SSISSIPPI$ &emsp; &emsp; &emsp; &emsp; &emsp;&emsp; 起始位置2S[3…11]= &emsp;&ensp; SISSIPPI$ &emsp; &emsp; &emsp; &emsp; &emsp;&emsp; 起始位置3&emsp;&ensp; .&emsp;&ensp; .S[10…11]=&emsp; &emsp; &emsp; &emsp;&ensp; I$ &emsp; &emsp; &emsp; &emsp; &emsp;&emsp;起始位置10S[11…11]=&emsp; &emsp; &emsp; &emsp;&emsp;$ &emsp; &emsp; &emsp; &emsp; &emsp;&emsp; 终结符字符串最后的$是人为添加的，这样保证后缀的唯一性，不会出现横跨多个字符串的后缀。 在平方时间类构造后缀树采用构建字典树方式构建（方法一）（1）将上述字符串的所有后缀加入到字典树中，得到如下结构：（2）将字典树中没有分支的路径压缩：要遍历所有的结点时间复杂度为 多边同步插入构建（方法二）这种方法的含义就是给定一个字符串，直接构造后缀树，不需要先构造字典树。在讲这个方法之前，需要先了解一些概念：在这里后缀树中的结点分为两大类，显示结点，隐士结点。显示节点就是那些分支处或者叶子节点，隐式节点是被压缩的那些节点。还有用来辅助构造后缀树的尾部链表，构造时，会沿着尾部链表进行更新。沿着尾部链表更新时的规则：我们通过例子来讲述这个更新规则，现在我们有字符串{ababcd$}，内部节点，叶子节点，隐式节点分别用不同的样式来表示。首先第一个字符a开始，构建如图所示，尾部链表从a的叶子节点指向根节点。现在我们插入下一个字符b，插入字符时说沿着链表进行更新的，这里先更新叶子节点，再更新根节点这个内部节点。这个是更新时的规则1，更新叶子节点时直接插入字符即可。这个是更新时的规则2，在更新到内部节点时的规则。根据这两条规则，我们可以对字符串{ababcd$}的b字符进行更新。这里更新叶子节点时，将b直接放置在a后面即可，然后沿着链表更新根节点，因为紧邻着根节点的字符只有a，不存在b，所以构造出一个新的节点b出来。这样做的主要目的，就是希望表示出，字符的所有后缀，现在的后缀有两个ab和b，这两个字符都必须出现在后缀树上。尾部链表会指向新出现的节点，最后指向根节点。下面我们沿着链表插入a，此时存在两个叶子节点，一个内部节点。沿着链表更新，首先更新最左边的节点，所以直接将字符a写后面即可。然后我们更新到右边的叶子节点，按照规则1也是直接写在后面。最后更新到根节点，紧靠着根节点的字符分别时左边的a和右边的b，根据规则2，我们不在构建新的节点，只是将左边a字符的节点做一个标记，因为现在的三个后缀是aba,ba,a，要在后缀树中全部体现出来。现在插入字符b在沿着链表更新时，叶子节点以及内部节点按照规则即可，但是会遇到隐式节点，现在会有规则3这个是更新时的规则3，在按照规则的前提下，不断进行更新。构建完成后如下图所示，这种方法每一次都要从头开始遍历尾部链表 后缀树与字典树的不同在于，它的边不再只代表单个字符，而是通过一对整数 [from, to] 来表示。其中 from 和 to 所指向的是字符串在文本中的位置，这样每个边可以表示任意的长度，以上就完成了后缀树的构建过程。在使用方法二时，需要遵守的规则： 123456规则1：遇到叶子节点时只需往叶子所在的边上面的字符串后面插入字符就好了，不用改变树的结构；规则2：遇到内部节点的时候，先看看插入的字符是否出现在显式节点后紧跟的字符 集合中,如果插入的字符出现在集合中，那么什么也不要做（是指不用改变构）， 因为已经存在了；如果没有出现，在显式节点后面增加一个叶子，边上标注为这个字符。规则3：遇到隐式节点时，先看看隐式节点后面的字符是不是当前将要插入的字符， 如果有则不用管了，没有则需要将当前隐式节点变为显式节点，再增加新叶子。 优化后缀树的构建是在方法二的基础上进行的优化，下面将哟用具体的例子进行讲解，给出的字符串为abcabxabcd$。首先构建字符a然后，依照之前的方法插入字符b,c。当我们插入下一个字符a的时候，会发现在后缀树中，存在字符a了。所以在这时，我们不能简单的插入。我们在按规则插入之后，要在字符a后做一个标记，就像之前讲的隐式结点，表示出有由a开始的后缀，a之后的字符就可以在这里操作。为了记录这些信息，我们需要引入一些概念：1、活动点（active point) 是一个三元组(活动结点,活动边, 活动长度)2、剩余后缀数（remainder） 还没有在后缀树中体现的后缀&emsp;&emsp;那对于上图，活动点是多少呢？答案是（0，a，1）0表示额就是根节点，在这个结点上进行活动。a表示的是会在由根节点周围a开始的那条边上进行相关操作，1表示的是在一位字符后操作，也就是a后，如果是2呢那就是在b后操作。&emsp;&emsp;此时还没有体现在后追树上的后缀数是1.也就是后缀a，因为我们并不能找到a这个后缀，我们只是在a后做了标记，表示接下来会有由a开始的标记。插入字符b和上面的a类似。此时的剩余后缀有b,ab两个，活动长度也变为了2。当插入下一个字符x时，x并不在后缀树中，显然，我们应该做一些别的操作了。此时，还没有体现在后缀树中的后缀有，{abx,bx,x}，此时我们要插入后缀abx后缀abx出现在了后缀树上，还没有体现的后缀是bx,x。我们会发现图中的活动边变为了b，活动长度也减少了，这样是为了让剩下的后缀更好的插入。在向根节点插入时，需要遵循规则1。现在还剩下的后缀时bx,x依次插入。此时活动点变为了（0（根节点），none(无活动边)，0(无长度)）,剩余的后缀是x。我们会发现图中多了一条=由4指向6的索引。这个就是另一条规则。这里的后缀连接类似于之前讲过的尾部链表，主要目的是为了节省插入时间，比如我们在插入ab开始的某个后缀后（例如abz），我们还需要插入bz，那就可以直接通过这个后缀连接插入b。在插入x后如上图所示。后面插入a,b,c因为这些字符都已经存在于后缀树里了，所以只需要做记录不需要操作，当我们插入到d时，这是一个新的字符，所以要处理所有的剩余后缀了，每当遇到新的字符，才会开始处理剩余后缀。此时的记录信息为：活动点(4,c,1)剩余后缀为abcd、bcd、cd、d。此时先处理后缀abcd，我们在记录处按照规则插入d。当我们处理完后缀abcd后，活动点变为了（6，c，1），活动结点直接从4变为了6，这个就是根据规则3来完成的。在优化后方法中，需要遵守的三个规则： 123456789规则1：当向根节点插入时遵循： 活动点保持为 root； 活动边被设置为即将被插入的新后缀的首字符； 活动长度减 1。规则2：如果我们分裂一条边并且插入一个新的节点，并且，如果该新节点不是当前 步骤中创建的第一个节点，则将先前插入的节点与该新节点通过一个特殊的指针 连接，称为后缀连接。后缀连接通过一条虚线来表示。规则3：当从活动点不为根的节点分裂边时，我们沿着后缀连接的方向寻找节点，如 果存在一个节点，则设置该节点为活动点；如果不存在，则设置活动点为根节点。活动边和活动长度保持不变。 在根据规则处理完所有的字符后，得到如图所示的后缀树，因为在整个过程中，只遍历了一遍字符串，且没有进行多余的结点操作，只是记录了一些信息，所以这个方法的时间复杂度是O(n)，可以在线性时间内完成。]]></content>
      <categories>
        <category>算法导论</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论：字典树]]></title>
    <url>%2F2019%2F07%2F29%2F%E5%AD%97%E5%85%B8%E6%A0%91%2F</url>
    <content type="text"><![CDATA[算法导论：字典树123定义：Trie树，即字典树，又称单词查找树或键树。是一种用于快速检索的多叉树结构。 Trie的核心思想是空间换时间。利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。优点：最大限度地减少无谓的字符串比较。 如果我们给定字符串集合为{b abc abd bcd abcd efg hii}，那么这个字符串的字典树为：对于一颗字典树来说，应该具有以下性质：第二条性质中的到某个结点，就是指到红色结点。 字典树的构建现在给出了，许多的字符串，我们从第一个字符串CAI开始构建。首先构建根节点，其次构建出CAI三个结点，现在构建字符串CAO因为CA已经存在，所以遍历到A，发现O结点并不存在，生成O结点。以此类推，最后生成的字典树，如上图所示。这个构建过程，每一次都相当于遍历了一个字符串的长度。假如有n个字符串，那么它的时间复杂度就是，n乘上字符串的平均长度。对于字典树，在空间上的花费为： 1空间花费：平均单词长度*结点长度*单词数 字典树的查询首先我们根据给出的单词，构建出了相应的字典树。现在，我们要对inn这个单词进行查询，当然是从根节点先开始。按照结点进行查询，最后可以找到inn这个字符串。那么它的时间复杂度就是这个字符串的长度O(len)。 字典树的插入现在我们要插入新的字符串atm，那应该怎么做呢？在走到t结点时，发现没有m结点，所以构造出m结点，并变为红色。 字典树的删除现在我们要删除字典树中的ant字符串，当然是从根节点开始去做一个查询。最后找到，结点t并且n结点也并没有其他分支，所以在删除时，会将n-&gt;t全部删除。最后结果如图所示，时间复杂度也为O(len)。 字典树的应用]]></content>
      <categories>
        <category>算法导论</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法导论：线性时间排序]]></title>
    <url>%2F2019%2F07%2F28%2F%E7%BA%BF%E6%80%A7%E6%97%B6%E9%97%B4%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[线性时间排序对于比较排序来说，在排序的最终结果中，各元素的次序依赖于它们之间的比较。我们可以看到下图中的比较排序算法，在最坏情况下情况下，时间复杂度至少O(nlgn)。从图中我们可以较为清楚的看到各算法的时间复杂度，下面将证明对包含n个元素的输入序列来说，在最坏情况下，时间复杂度至少都是O(nlgn)。比较排序可以被抽象为一颗决策树，那什么是决策树呢？比如上图所示，现在要出去相亲，首先判断年龄，如果大于30岁，那就直接不见了，小于30再考虑其他条件。之后，我们依次判断了，长相，收入，都满足了要求，于是决定去见上一面。决策树是一颗完全二叉树（美式定义：要么有左右孩子、要么就没有孩子），非叶子结点都是一个逻辑判断，每个分支都是判断结果。 如上图所示，现在有三个数x,y,z。我们可以构建出如图所示的决策树，根结点是x和y比较，如果x≤y，再比较y和z的大小，如果x≥y，则比较x和z的大小。这里有三个数，并且是互异的，所以大小排列情况会有6种，如果有n个互译的数，那就是n!种。当x=6，y=8，z=5时，最后就会得到&lt;z,x,y&gt;这个结果，也就是&lt;5,6,8&gt;。在最坏情况下，比较的次数，就是树的高度，2的h次方表示的是，总共的结点，肯定比叶子结点多，最后可以解出，h是大于等于O(nlgn)的。介绍完了比较排序的时间复杂度，现在该介绍线性时间排序了。 计数排序12问题描述：给定一个无序的序列，对序列进行排序，使之成为有序。基本思想：对于每一个输入元素x，确定小于x的元素个数，可以直接把x放到它在输出数组中的位置上,但是需要略微修改，因为一个位置不能存放两个元素 算法的主要思想就是找到比元素x小的元素个数，元素x是待排序的元素。那这个排序过程如何实现的呢？A数组就是我们的待排序序列{2，5，3，0，2，3，0，3}，C数组是用来记录比元素x小的元素个数，因为A中的数是0-5，所以B中的数组大小也是0~5，上标表示的就是A中的数。我们现在先记录，每个元素的个数是多少，现在指向2所以2的个数标记为1。指向5，所以5的个数变为1。在完成后，数组C中记录下了，各元素的个数。不过我们最终要的结果是记录下比元素x小的元素个数，所以这里面的数字还要进行简单的变换。现在我们将1中的0变更为2，这个数字表示的是小于等于1的数，也就是2，下面我们再记录小于等于2的数。小于等于2的个数，就是前面小于等于1的个数，再加上2自身的个数，结果为4。在完成更新后，所得如上图所示，每个数组中记录的数，就是小于等于自身的元素的个数。B数组就是我们最后的排序结果，对A数组从右向左进行遍历，这样是为了让排序是稳定的，排序的稳定是指，对于相同的数字，比如这里的2，在排序完成后，并不改变它们的相对次序。这里我们对3进行排序，去B数组查找，小于等于3的个数，找到为7就直接放在上标为7的数组中，并且将B中记录的数字减1。排序完成的结果，如图所示。因为要遍历两遍A数组，以及遍历一遍B数组，所以时间复杂度为O(n)+O(n)+O(k)=O(k+n)，当k=O(n)时T(n)=O(n)。 基数排序12基本思想：基数排序的总体思路就是将待排序数据拆分成多个关键字进行排序，实质是多关键字排序。注意事项：选择低位优先排序，因为如果按照高位优先排序的，当排到次高位时，还需要返回看高位数字,相对来说比较麻烦。 例如，现在给出了7个数字，我们要对其进行排序，在这种位数很多的情况下，我们优先选择的就是基数排序。在基数排序时，优先对个位数进行排序，也就是最右边的那位数。要对个位数数字进行排序，那选择什么样的方法对其进行排序呢？只要是线性时间的排序，都是可行的，这里我们选择之前讲过的计数排序。再对十位数上面的数字进行排序。在完成排序后，可以得到上图的结果。时间复杂度分析：每个数字都是d位数，比如说这里都是三位数。每一次排序，都是计数排序，时间复杂度为O(n+k)，总共d次计数排序。所以时间复杂度为O(n+k)d=O(d(n+k))。 桶排序一般来说，只有在输入数据是给定的一个范围内，并且还是服从均匀分布的，才会使用桶排序。A中就是给出的数据，这些数据都是0到1之间的数，B中就是我们准备的10个桶，数字0到9表示的是数据小数点后一位的数。开始进行排序，第一个数字是0.78，所以放在了7号桶里面。当进行到0.72时依然是放到7号桶里面，不过要和0.78比较一下大小，然后进行排序。最后的排序结果，如图所示。]]></content>
      <categories>
        <category>算法导论</category>
      </categories>
      <tags>
        <tag>算法导论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读：Maverick: Discovering Exceptional Facts from Knowledge Graphs]]></title>
    <url>%2F2019%2F07%2F27%2FMaverick%2F</url>
    <content type="text"><![CDATA[论文阅读：Maverick: Discovering Exceptional Facts from Knowledge Graphs原文链接参考资料：知识图谱介绍 123论文题目：Robust Entity Resolution using Random Graphs发表时间：SIGMOD’18,June 10-15, 2018, Houston, TX, USA论文作者：Gensheng Zhang 、 Damian Jimenez、 Chengkai Li 论文作者详细资料： 2002-2006武汉大学。2010-2012南达科他州立大学。2012年至今德克萨斯大学阿灵顿分校研究方向：数据挖掘，图形挖掘，数据库德克萨斯大学阿灵顿分校博士。研究兴趣：NLP，神经网络。Chengkai Li博士是德克萨斯大学阿灵顿分校计算机科学与工程系副教授，创新数据库与信息系统研究实验室（IDIR）主任。 Introduction这篇论文的题目是从知识图谱中发现异常事实，所以首先要了解知识图谱。知识图谱是一个将现实世界映射到数据世界，由结点和边组成的语义网络。其中结点代表物理世界的结点或者概念，边代表实体的属性或者结点的关系。因为现实世界中的物体充满着各种各样的关系，知识图谱就是一种合理摆放他们的方式。例如在上图就是知识图谱，其中结点表示了，人物和水果。例如最上面那条边，表示了May喜欢橘子这个水果。其实知识图谱最开始是由Google提出的，为的就是解决搜索的问题，例如我们可以在谷歌上搜索居里夫人。我们可以在搜索界面上看到这样的结果，在右边红色方框的结果就是因为有知识图谱的帮助，所以可以很快的显示出结果。其中左边显示的结果，她是唯一获得两种不同学科诺贝尔奖的人，也是巴黎大学的第一位女教授，这个就是我们要找的特殊事实。Maverick就是这篇论文提出的处理系统，现实世界里的各种知识会被总结为知识图谱，这个时候，如果我们想了解居里夫人的特殊事实，就对Maverick输入居里夫人，最后会得出关于居里夫人的前k个特殊事实。 Our Approach这是关于世界杯的知识图谱中的一部分，S表示运动员，G表示一个进球。ESP表示西班牙，BRA表示巴西，CRO表示克罗地亚。边上的play-for表示某球员是属于某个国家的，scored-by表示这个进球是由指向球员踢进的，awarded-to,表示进球的这一分，是属于指向的球队的，图中红色圆圈的部分，表示的是：巴西国家队的球员S3踢进了G3这个进球，这一分属于巴西队。我们可以看到G1，G2，G3这三个进球中，只有G1是属于克罗地亚队得分的球，其他球是巴西队得分，所以在所有进球的这个背景中，G1是属于特殊的那一个，而且我们还可以发现，G1是一个乌龙球，也与其他两球不同。那在知识图谱中是如何得出G1是一个乌龙球的呢？首先找出G1,G2,G3这三个进球，所踢进的球员，以及这些球员效力的国家队，也就是在右边的三个Match。因为我们现在是要找出，这三个球中的特殊情况，所以必须要放在一定的背景里，才能发现其中的不同，比如我们说居里夫人是唯一得过两次不同学科诺贝尔奖的人，是把她放在所有得过诺贝尔奖的人里去比较得来的。所以，这里我们将这些球都放在巴西队进球的这个背景里，那可以从这个背景里得出怎么样的结论呢，再根据每个进球边上的awarded-to属性，可以得出G1是一个不同的进球，它是一个乌龙球。前文所讲，我们需要通过知识图谱上面的各种Match找出各种模式，最后的结果就是找到Context，也就是找到我们应该放到什么背景里去比较。这个图那就是代表Maverick的一整个执行流程。首先左上角是知识图谱，Maverick将其中的模式都通过Pattern Generator来生成，再结合context（也就是比较的背景）放到Exceptionality Evaluator中，来选出前k个特殊事实。那模式构造是怎么样的呢？这里是通过树来构造的，比如这里根结点的g表示的就是所有的进球，g的子节点，就多了一些限制，比如第一个，表示球员S1踢进的所有进球。生产的过程，就是首先根据根节点p0，这里也就是g，通过Context Evaluator来寻找到和g有关的match，最后总结出新的模式，得到p1,p2,p3,p4。如果去进行所有的评判，那工作量太大，所以我们只能选出一部分Pattern去进行比较，这里使用集束搜索，设定宽度为2，再使用启发式算法，选出满足要求的两个。在进行完Pattern Tree的构建后，Maverick的流程图变为上图所示。现在只剩下，异常评估的这一部分，还没有完成。我们判断异常必须要结合属性，所以在这一块，会将属性构建为属性树。在构建属性树时，也会遵循一定的规则，如果这里有三个属性，a1,a2,a3，会按照这个顺序，如上图所示，进行树的构建。但是为了减少工作量，也会对其进行减少，会设定一个阈值达到的就保留，无法达到的就去掉。这个就是处理问题完整的流程图，选出top-k个异常值。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读：Robust Entity Resolution using Random Graphs]]></title>
    <url>%2F2019%2F07%2F26%2FRobust-Entity-Resolution%2F</url>
    <content type="text"><![CDATA[论文阅读：Robust Entity Resolution using Random Graphs原文链接参考资料：数据中国 123论文题目：Robust Entity Resolution using Random Graphs发表时间：SIGMOD’18, June 10-15, 2018, Houston, TX, USA论文作者：Sainyam Galhotra 、 Donatella Firmani、 Barna Saha 、Divesh Srivastava Indroduction论文的意思是利用随机图，来完成实体解析(Entity Resolution),那么何为实体解析呢？根据《实体解析与信息质量》，可以了解到： 123实体解析（Entity Resolution）是一种用于判断两条记录是否指向同一事物的过程。实体这个术语描述了过程的目标是真实世界的事物，比如某个人，地点或者物品。而解析则描述了回答这样的一个问题的过程：两条不同记录是否指向了同一个真实实体？ 尽管实体解析的定义描述的是两条记录之间的关系，但事实上，这个定义也可以被延伸到一个更大的记录集合上，相应的，该过程的输出则聚合了指向同一实体的所有记录的子集/簇。在这样的上下文中，ER的定义也可以解释为：“识别并整合所有定义同一真实世界实体的记录的过程”（Benjelloun,Garcia-Molina, Menestrina, et al., 2009）。例如在上图中，实体解析的意思就是，判断出有哪一些表示的是同一个物体，比如上面的iPhone Two和iPhone 2表示的就是同一个手机。又如上图中，实体解析就是选出哪些照片表示的是同一个人，这里有古天乐，周星驰，张震。 Previous approach这里介绍以前的方法，我们用上面提到的判断照片是否是同一个人举例，这样做的前提是我们已经得出了，这两个照片是同一个人的概率是多少。怎么得出呢，微软提供了这个服务。Microsoft tool TwinsOrNot可以在这个网站，上传照片进行对比识别。在进行完，上传对比之后，我们可以得到，上面的概率图，其中绿色就表示为同一个人概率超过0.5的，红色就是低于0.5，线越粗，概率越高，红色虚线说明概率极低。得到概率图之后，就要在此图上运用方法找出所有同一个人的照片了。在这种方法里，只要是绿色连接的照片我们就认为是同一个人，以此来进行划分，得到结果。显然这种方法并不准确，高度依赖于事先判断的概率，这里就把张震和周星驰当作了同一个人。每条边上都有相似的概率，这种方法就是把概率特别相近的划分到一起，当作是同一个人。我们可以从上图中看到，这种方法也是错误的，它并没有把所有的周星驰照片都找出来（因为年轻的周星驰和年老的周星驰相似概率并不高）。正确的划分得到的应该是如图所示的这样，分成了三个组，找出了古天乐、周星驰、张震。为了准确的找出所有的人，引入了Oracle这个概念，并不是指的数据库公司，而是表示为一种众包的抽象。因为在很多情况下，人去判断是否相似，是要比计算机容易很多的。例如： 1Online advertising = Internet ad 人们可以很快的判断出这两者都是网络广告的意思，但计算机却很困难，所以提出的Oracle相当于是一个系统，可以回到如下的问题。而且我们假定，Oracle总是会回答正确。我们有了Oracle，并且Oracle总是会给出正确的答案，显然可以通过Oracle来回答两张照片是否是同一个人这种问题。那应该如何觉得询问的顺序呢？也就是应该选择哪两张照片去询问呢。这里有两种方式，其一就是普通的方式，随机选取一对进行询问，显然这种方法是耗时、耗力的。其二就是聪明的方法，根据概率的大小去进行询问，先询问概率大的，因为他们更可能是同一个人。通常来说，以前使用的方法就是按照边的概率进行询问的方法。在这里我们先访问古天乐那条边，得到的结果是是同一个人。然后询问其他的边，得出了正确你的结果。在询问完成后，得出了正确的结果，完成了实体解析。我们假设的是Oracle总是给出正确的结果，但是如果Oracle给出了错误的结果，例如在上图中把周星驰和张震当作一个人，那么我们最后的实体解析就是错误的。 Our approach以前的方法，都是假设Oracle一定会回答正确，但是实际情况中Oracle并不总能回答正确，会得到错误的结果。所以这篇论文就提出了，一个纠正错误的工具。这是这篇论文中，实体解析的处理流程，实现进行记录的收集，也就是上图的收集那些照片，再之后就是使用前文所讲的策略，以及本文提出的纠错层。这个纠错层的关键思想有两方面： 12在并入新结点时，进行多次的判断。通过合并以及分裂过程来进行纠错。 在并入新结点时，我们不再只是查询一对，而是查询许多对，如上图中要将New Node并入其中时，我们会对许多对进行判断，如果相似的值达到了阈值，则认为时一个人，将新结点放入其中。 合并过程主要是为了提高recall，也就是召回率，意思就是希望可以找到所有的同一个人照片。主要的过程就是，在两个聚类中的结点，不断的进行询问，判断是否为一个人，然后决定是否合并。在已经完成的聚类里面，会存在Low confidence node ，就是纸盒部分结点连接，比如图中的张震，这种结点，就很有可能，并不属于这个聚类。所以我们应该想办法对其进行判断。解决的办法，就是判断Low confidence node和其他结点的相似度，如图中，判断出不相似，那就将其剔除。前文所说，这是一个纠错的工具，所以会有使用上面的不同，这里介绍了三种不同的使用方法： 123使用方法一：Eager:每一次查询，都使用这个纠错的工具。这样会降低效率，召回率降低，就是不能找到所有的同一个人的照片，但是准确度会变高。 12使用方法二：Lazy:不使用纠错的工具。这样会让准确度降低，但是召回率变高。 123使用方法三：Adaptive pipeline:高概率的结点就不适用纠错工具，就是两张已经很相似的照片，不会再使用工具询问。 Experiments上图是在不同的数据集上做的实验，横坐标表示查询的数量，纵坐标表示效果，得分越高，效果越好，从图中看出，Adaptive pipeline的效果是非常好的，仅次于理想情况。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读：Dynamic Bike Reposition: A Spatio-Temporal Reinforcement Learning Approach]]></title>
    <url>%2F2019%2F07%2F25%2FDynamic-Bike-Reposition%2F</url>
    <content type="text"><![CDATA[论文标题：通过强化学习，实现自行车的动态调配原文链接参考资料：莫凡的个人网站 123论文题目：Dynamic Bike Reposition: A Spatio-Temporal Reinforcement Learning Approach发表时间：KDD 2018，August 19-23,2018论文作者：Yenxin Li Yu Zheng Qiang Yang 论文作者详细介绍：&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Yenxin Lin是香港科技大学的学生&emsp;&emsp;&emsp;&emsp;杨教授现任香港科技大学计算机科学与工程系讲师。他的研究兴趣包括机器学习，人工智能和数据挖掘。&emsp;&emsp;&emsp;&emsp;京东金融副总裁，首席数据科学家。 主要任务是利用大数据和人工智能技术解决交通和城市规划等城市挑战。1.Introduction这篇文章所讲的自行车的动态调配，并不是指的共享单车，而是下图所示的比较传统的自行车站，这主要是因为课题研究的时候，共享单车还没有火，并且论文所使用的数据是英国的数据，那边没有共享单车。在整个地区的自行车站点里，总是会有一些站点缺少自行车，而有些站点的自行车过多，一般需要通过运输的方式将自行车进行调配，这篇论文解决的就是如何调配，也就是应该从哪一个站点运输多少辆自行车到其他某个站点去。2.Our approach一个市的面积是很大的，我们不可能在整个市的所有自行车站点之间进行自行车的调配，这是不必要的，同时也会浪费大量的人力、物力、财力，所以我们应该减少，调配自行车的范围，比如现在有7个自行车站点，我们不会在这7个站点之间进行自行车的调配。在这7个站点，我们会根据规则对其进行划分，规则如下： 121.两个站点之间的距离要接近，相隔太远是无法划分到一个区域里面的。2.有着相同的行车轨迹，比如小区周围的自行车站，都会到一些办公的区域去，这就是共同的行车轨迹。 最后这7个站点，可以根据这些规则划分为两个区域（这里只是举个例子）：因为这些区域地理位置相近，且行车轨迹也大致相同，现在我们将分好的区域作为单位去考虑自行车调配的问题，但是即便如此，从城市的角度来看，我们也不需要在所有不同的区域之间进行自行车的调配。比如在下面的上海地图中，上面的圆圈表示的就是区域，人们一般不会从松江骑个车到静安区，所以考虑整个城市所有区域的调配是不必要的。所以，我们可以将区域分成不同的组，只在组之间进行调配，这样可以大大的节省下资源。显然，现在的问题，就是应该如何去分组保证调配的合理。区域分组的过程分成了三个步骤： 123Step 1:根据这两个区域之间的通勤记录进行连接，通行频率高于给定阈值的就进行连接。Step 2:社区发现，一个区域连接的不同区域越多，说明越有可能形成一个社区，只与几个相连，那我们就将这个连接给去掉。Step 3:将那些剩下的结点，根据已有的聚类算法，合并到某个组去。 现在已经完成了区域分组，我们只会在组内，进行自行车的调配，组与组之间的调配，我们是忽略不计的。到现在，要解决的问题就是，如何在组内进行自行车的调配，也就是找到调配自行车的策略，这篇论文使用的就是强化学习的方法。所以下面简要的介绍一下，强化学习是什么：强化学习就是像图中的小朋友一样，一开始什么都不懂，然后经过不断的试错，掌握了知识，找到了正确的方法。强化学习就像是一个人，第一次见到火，他不知道这是什么。但是他感觉到了温暖，所以他觉得火是好的，并且想要更靠近火。在触碰了之后，被火给烫到了，他学会了不能离的太近，也不能去触碰火。在经过这一学习过程后，他学会了，要适当的保持距离，不能触碰。强化学习就如下图所示，我们做出某些行为，得到反馈，我们对环境进行观察，最后不断学习的过程。强化学习的分类方法有很多，这里的分类就是按是否基于模型来分类的，下面进行详细的介绍。不基于模型的强化学习，就是只能通过现有的观察来得出结论，进行学习。比如这里有一个机器人，它想知道在地球上扔一个原子弹会发生什么，它这样做了，然后把自己给炸死了。基于模型的强化学习，现在这个机器人也要做同样的事情，但是它是基于模型的，所以它拥有了想象力，它可以再做出一个地球的模型，然后在这个假的地球上做实验，得出结论。Model-Free RL只能够做一步，看看反应，然后再做，最后完成学习的过程，它是没有想象力的。Model-Based RL就是可以想象出做了之后的事情，然后可以从中选择一个去执行。下面是用神经网络实现的强化学习过程，输入现在的状态和动作，神经网络会根据反馈给这个动作打一个分。回到论文中来，我们会利用强化学习，来完成自行车调配问题，输入现在各自行车站点的信息，比如数量，和运输车的信息，再还要输入可能会做的许多的调配行动，选择神经网络里面分数最高的一个去执行。为了让神经网络能判断的更准确，还加入了一个模拟器，用来模拟自行车的归还需求，以及租界需求，当然是在一定的时间里面进行的模拟。在这个过程里，根据神经网络的判断进行自行车的运输，之后会得到反馈，这些记录都存放在样本池里面，用来供神经网络学习，使其判断的更准确。自行车的动态调配过程： 12341.Cluster : 在图中的Region Clusters部分，也就是上文所讲的分组过程，我们只会在组内进行自行车的调配。2.Current state : 将现在的状态输入，也就是天气、自行车数量、运输车位置。3.network ： 通过神经网络来确定我们所要执行的调配策略。4.Reposition : 执行这个调配自行车的动作。 3.Experiment图中的数字表示的是顾客减少量，也就是没有骑到自行车的人，从图中我们可以看到，使用STRL也就是本文所介绍的方法，顾客的损失量是最少的，也即是效果最好。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eclipse导入java项目后，出现错误提示的解决办法]]></title>
    <url>%2F2019%2F07%2F25%2Feclipse%E5%AF%BC%E5%85%A5java%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[在将一个java项目导入后，可能会出现许多的错误提示，例如： 这些错误可能是由于jdk版本不同所导致的，那应该如何解决呢？1.右键项目，点击Build Path中的Configuer Build Path2.在Libraries中将那个有红叉的JRE的移除，再点击Add Library,添加新的3.在出现的弹窗里选择JRE System Library，一直点下去就好了。]]></content>
      <categories>
        <category>踩过的坑</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装Mysql时端口号3306被占用的处理方法]]></title>
    <url>%2F2019%2F07%2F25%2F%E5%AE%89%E8%A3%85Mysql%E6%97%B6%E7%AB%AF%E5%8F%A3%E5%8F%B73306%E8%A2%AB%E5%8D%A0%E7%94%A8%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[有些情况下端口号3306会被占用，例如我们卸载了Mysql重新安装时就会出现这种情况。解决方案如下：1.打开命令窗口（windows+R,输入cmd）2.输入命令 netstat -ano（查看端口的使用情况）同时我们需要记住，后面的PID数字，也就是这里的47483.打开任务管理器4.点击查看详细信息在这里可以点击PID，它会按照从小到大的顺序排列，之后找到4478，右键关闭即可。]]></content>
      <categories>
        <category>踩过的坑</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDBC的连接设置问题]]></title>
    <url>%2F2019%2F07%2F25%2Fjdbc%E7%9A%84%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[1mysql版本：community-5.7.17.0 在连接时，需要书写的： 1234driverClassName=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/web01?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=trueusername=rootpassword=root 上面的useUnicode=true&amp;characterEncoding=UTF-8都是用来完成编码的设置，而useSSL=true建立SSLl连接。如果未明确设置，MySQL 5.5.45+, 5.6.26+ and 5.7.6+版本默认要求建立SSL连接。 若未设置，则会出现下列警告： 1234WARN: Establishing SSL connection without server’s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn’t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to ‘false’. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification. 在jdbc的配置中如果myaql是6.0及以上的，会有所不同，需要按照以下设置驱动： 1driverClassName=com.mysql.cj.jdbc.Driver 否则就会报错： 12Loading class &apos;com.mysql.jdbc.Driver&apos;. This is deprecated. The new driver class is &apos;com.mysql.cj.jdbc.Driver&apos;. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. 同时mysql 6.0以上还需要设置时区： 1url=jdbc:mysql://&lt;u&gt;localhost&lt;/u&gt;:3306/ssm_spring?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=true&amp;serverTimezone=UTC 不过值得注意的是UTC代表的是全球标准时间，我们使用的是北京时区，领先UTC八个小时。所以我们可以将时区设置为： 1serverTimezone=Asia/Shanghai]]></content>
      <categories>
        <category>踩过的坑</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[错误提示：The reference to entity "useSSL" must end with the ';' delimiter.]]></title>
    <url>%2F2019%2F07%2F25%2FXML%E4%B8%AD%E7%9A%84%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[###XML中的特殊字符XML中总共有5个特殊字符，如果配置文件中要写这些特殊字符的话，就需要进行特别处理。 使用XML转义序列表示这些特殊的字符，这5个特殊字符所对应XML转义序列为： &amp; 替换为 &amp;amp;&lt; 替换为 &amp;lt;&gt; 替换为 &amp;gt;&quot; 替换为 &amp;quot;&#39; 替换为 &amp;apos;（后面的 ; 替换字符中的一部分，也要一起写入的）]]></content>
      <categories>
        <category>知识总结</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读: Streaming Graph Partitioning: An Experimental Study]]></title>
    <url>%2F2019%2F07%2F25%2FStreaming-Graph-Partitioning%2F</url>
    <content type="text"><![CDATA[论文阅读：Streaming Graph Partitioning: An Experimental Study123论文标题：Streaming Graph Partitioning: An Experimental Study发表：PVLDB, 11(11): 1590-1603, 2018作者：Zainab Abbas、Vasiliki Kalavri、Paris Carbone、Vladimir Vlassov 原文连接 作者详细介绍： 12姓名：Zainab Abbas院校：皇家理工学院（瑞典）的研究生 123姓名：Vasiliki Kalavri院校：皇家理工学院（瑞典）的博士研究方向：分布式数据处理和大规模图形分析 123姓名：Paris Carbone院校：皇家理工学院（瑞典）的博士研究方向：分布式系统、数据管理 123姓名：Vladimir Vlassov院校：皇家理工学院（瑞典）的教授研究方向：数据密集型计算和流处理; 云资源管理; 基于云的服务和应用程序 前言现实世界数据量十分巨大，而这些数据大多都是用图来表示的（如下图所示），所以处理图的数据，对现实世界是至关重要的。而在计算中，图的分布式计算是重要的，分布式计算，必然带来图的分区。 在进行分区之前，我们来看看完整的处理图数据的过程 大致上分为三步， 首先将图数据加载，然年后进行分区，最后是计算过程。在分区之前，通用图分区方法扫描完整图以获得结构特征。 然而，对低延迟，连续图形分析的新兴需求导致了在线分区方法的发展。 在线方法将边或顶点作为流摄取，而不是提前完整的加载。 在图处理过程中一般的图分区方法 分为两种，也就是Edge-cut和Vertex-cut，Edge-cut的意思就是切边，对结点进行分区，让边跨越各个分区，这种方法不需要构造其他结点。Vertex-cut就是切结点，对边进行分区，会判断每条边应属于哪一个区，显然不同的边有可能连接着同一个结点，并且这些边也分在不同的区，所以结点要进行复制，跟着边走，边在哪里，结点就在哪里。如图所示，复制了z结点，以及d结点。 流图分区所以对于这篇论文所讲的流图分区来说，主要也是这两种方法。流图分区中的流，分为两种，一种是边流，一种是结点流。边流就是不断有边数据流入，然后对其判断边属于哪个分区。结点流就是以结点的形式流入。 Streaming Graph Partitioning本文所讲的流图分区，大致分为三类 1231. Vertex Partitioning Methods（结点流，对结点进行分区）2. Edge Partitioning Methods （边流，对边进行分区）3. Model-Agnostic (其他方法，混合各种方法使用) Vertex Partitioning Methods(按结点的分区方法)按结点分区的大致过程如下图所示，左边表示原始图形，共有6个结点（0，1，2，3，4，5），上面的表格表示图的输入顺序，（0：1）表示输入的是0号节点，同时记录和它相邻的结点1号。这里输入的顺序是随机的。结点的分区共有三个，分区数量是提前确定的。最后生成右下角的分区图形。 这个分区方法所使用的原理就是Linear Deterministic Greedy (LDG) 1线性确定性贪婪分区（LDG）尝试将相邻顶点放置到同一分区，以减少边缘切割。在满足容量约束的同时，将一个顶点分配给包含大多数邻居的分区。 如下图所示，在某个分区中存在1号和4号结点，我们现在要判断2号节点所在分区，根据LDG我们会选择2号结点邻居最多的分区，所以最后会将1，2，4三个结点放在同一个分区。 不过这样会存在问题，就是所有的结点可能都会在同一个区里。（比如说放置了第一个结点，第二个是它的邻居会放在一起，之后也是如此） 为了解决这个问题，我们会给每个分区里的结点数量进行限制，其中C就是最大的容量，根据结点个数以及分区的个数计算出来。所以这种方法需要知道图的全局信息，比如结点数量。 Edge Partitioning Methods(按边的分区方法)这种方法就是判断每条边，应该属于哪一个分区里面，过程如下图。上面的表格就是输入流，（3，2）表示从结点3指向结点2的边。按照箭头顺序输入，这里是随机输入。黄色结点是复制的结点。 显然对于按边分区的方法来说，复制结点越多，就代表着这种分区是不好的，所以我们在进行按边分区的时候，应该尽可能的减少结点的复制，于是解决的办法就是首先复制那些度高的结点，比如说图中红色的结点，这样能减少总体的复制次数。那具体的过程是怎样的呢？首先我们输入边，并且边上的结点都不属于任何分区，如图所示，这里有三个分区，用三种颜射表示。在这种情况下，我们会将这条边放在负载最低的分区里，也就是边最少的分区里。如果输入的边其中一个结点属于某个分区，另一个不属于任何分区的话，就将这条边放置在结点属于的那个分区里面，也就是下图中蓝色的区。两个结点，其中一个属于多个分区，另一个也属于某个分区，并且有交集，那这条边就会放在有交集的区里，也就是下图橙色的区。如果这两个存在属于不同的分区，却没有交集，根据HDRF也就是先复制度高的，所以我们会复制下图中左边的结点。结果如下 Model-Agnostic (其他方法，混合各种方法使用)其他方法里面也有许多种，这里介绍一下哈希的方法。对于低度数的点，我们会对本身结点进行哈希，比如这里的4号结点，我们会对4进行哈希运算，然后将4号结点，以及所有的入边都分配到这个块中。 对于高度数的顶点，我们会对源节点进行哈希，比如这里的1号结点，我们会对2号和5号结点进行哈希，然后按照2号和5号的结果，分配到块中。 这种方法需要知道图的全局信息，还要知道机器数，比如这里的机器数是三，那么求哈希值的时候，就是除以3求余数。 这种方法是边分区和结点分区一起使用的，混合方法。高度顶点和低度顶点的区别是用给定的阈值来区分的，并且首先要确定好分区数量。Experiment这个实验中，我们设置的分区数是4分区性能就是指每秒钟的吞吐量，意思就是指每秒钟把多少结点或者边，分配到某一个区里面去。我们的结果表明Hash分区在吞吐量方面优于所有其他评估方法。 然而，性能的差异并不显着。 在这两个实验中，Hash显示的吞吐量最多比第二个最佳分区方法高2倍，并且随着图的增大，这个差异也在减小。 这里将Twitter和Friendster的分区数设置为16，剩下两个较小的分区数设置为4.A good partitioning method is not only fast but also pro-duces high-quality partitions（不仅要分的快，还要分的好）所以要评判分区的质量。对于按结点的分区来说，我们用edge-cut指标来评判分区的质量，edge-cut越多，说明分区质量就不太高，因为通信成本大大增加了。入就是这个指标对于按边分区的方法来说，我们用结点的复制次数来评判分区的质量，如果复制的次数太多，说明分区的质量不太好。图b就是这个指标。在最后，我们还要考虑负载均衡的问题，也就是分布的较为平均的意思，不能所有的结点或者边，都在一个区里面。哈希的负载均衡是最好的，因为是完全随机的分配的。 算法的性能也和输入的结点或者边的顺序有关，比如这里是使用随机输入，或者DFS输入，都对算法性能有着很大的影响。]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL WorkBench 如何运行sql文件，将其变为数据库]]></title>
    <url>%2F2019%2F07%2F25%2FMySQL-WorkBench%2F</url>
    <content type="text"><![CDATA[MySQL WorkBench 如何运行sql文件，将其变为数据库 环境：win10软件：mysql community 5.7.17.0操作时间：2019/7/1 在sql文件里，已经有了生成数据库的语句，这样执行才会生成数据库。下面是操作步骤：1.打开WorkBench进入操作界面 会看到如下图： 2.运行sql文件找到运行sql脚本处： 选取sql文件： 3.生成数据库最后生成的数据库会显示在图中圈出来部分：]]></content>
      <categories>
        <category>踩过的坑</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java JDBC编程流程步骤]]></title>
    <url>%2F2019%2F07%2F25%2FJDBC%2F</url>
    <content type="text"><![CDATA[JDBC：Java Data Base ConnectionJDBC是用于运行sql语句并从数据库中获取新新的java API.JDBC是用来（让我们的程序）通过网络来操作数据库的，作用非常重要；JDBC技术也是Java核心技术之中的一个。是使用JDBC驱动程序訪问数据库的首选方式JDBC总共分为6步： 1234561、注冊驱动 2、建立连接 3、创建运行SQL的语句4、运行语句 5、处理运行结果6、释放资源 第一步：注册驱动推荐使用方式： 1Class.forName(“com.mysql.jdbc.Driver”); 如果mysql版本高，需要写为： 1Class.forName(“com.mysql.cj.jdbc.Driver”); 第二步：建立连接通过Connection建立连接，Connection是一个接口类。其功能是与数据库进行连接。使用方式为： 1 Connection con =DriverManager.getConnection(url, user, password); 其中user，password就是数据库的用户名和密码，示例如下： 123url=jdbc:mysql://localhost:3306/web01username=rootpassword=root 第三步：创建运行对象由Statement运行sql语句，不过我们一般使用派生出的PreparedStatement。PreparedStatement能够对SQL语句进行预编译，提高了安全性。 1PreparedStatement ps=connection.prepareStatement( &quot;update user set id=? where username=?”); sql中由?表示占位符，再通过 1ps.setObject(1, object); 来设置值，1就表示第一个问号，也就是id ，Object就是我们要设置的值。第四步：运行sql语句reparedStatement 提供两个经常使用的方法来运行SQL语句。 executeQuery(Stringsql),该方法用于运行实现查询功能的sql语句。返回类型为ResultSet（结果集）。如： 1ResultSet rs =st.executeQuery(sql); executeUpdate(Stringsql),该方法用于运行实现增、删、改功能的sql语句，返回类型为int，即受影响的行数。如： 1int flag = st.executeUpdate(sql); 第五步：处理运行结果 ResultSet对象 ResultSet对象负责保存Statement运行后所产生的查询结果。例如我们可以打印出里面的值： 12345while (rs.next()) &#123; System.out.println(rs.getInt(&quot;id&quot;)+&quot;,&quot;+rs.getString(&quot;username&quot;)+&quot;,&quot;+rs.getString(&quot;password&quot;)); &#125; rs就是ResultSet。第六步：数据库资源不关闭，其占用的内存不会被释放，所以要进行关闭。要按照和打开相反的顺序，先打开的后关闭，后打开的先关闭。 12345678打开Connection con = DriverManager.getConnection(url,&quot;root&quot;,&quot;root&quot;);PreparedStatement pstmt = con.prepareStatement(sql); ResultSet rs = pstmt.executeQuery();关闭rs.close();pstmt.close();con.close();]]></content>
      <categories>
        <category>知识总结</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>java</tag>
      </tags>
  </entry>
</search>
